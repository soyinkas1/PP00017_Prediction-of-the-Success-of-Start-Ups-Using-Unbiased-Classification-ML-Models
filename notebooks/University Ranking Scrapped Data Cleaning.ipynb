{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d6dedf",
   "metadata": {},
   "source": [
    "**Add the scraped university ranking data and see if it can enrich dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_df = pd.read_csv('D:\\\\OneDrive\\\\Documents\\\\PERSONAL\\\\PERSONAL DEVELOPMENT\\\\DATA SCIENCE\\\\Personal Project Portfolio\\\\PP00017_Prediction of the Success of Start-Ups Using Unbiased Classification ML Models\\\\test.csv')\n",
    "uni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column for rank and rename the rank_name column\n",
    "import re\n",
    "#     tweet =tweet.lower()# Lowercasing all the letters\n",
    "#     tweet= re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet) # Remove all the mentions\n",
    "#     tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", tweet) # Remove all the hashtags\n",
    "#     tweet = re.sub(r\"http\\S+\", \"\", tweet) # Remove the URL\n",
    "#     tweet = re.sub(r\"www.\\S+\", \"\", tweet) # Remove the URL\n",
    "#     tweet= re.sub('[()!?]', ' ', tweet) # Remove punctuations\n",
    "#     tweet = re.sub('\\[.*?\\]',' ', tweet) # Remove punctuations\n",
    "#     tweet= re.sub(\"[^a-z0-9]\",\" \", tweet) # Remove all non-alphanumeric characters\n",
    "for row, col in enumerate(uni_df['rank_name']):\n",
    "    uni_df.loc[row, 'name'] = re.sub(\"[^a-zA-Z' ']\",\"\", col)\n",
    "    uni_df.loc[row, 'rank'] = re.sub(\"[^0-9–' ']\",\"\", col)\n",
    "    uni_df.loc[row, 'rank'] = re.sub(r\"(\\d+)–\",\"\", uni_df.loc[row, 'rank'])\n",
    "    uni_df.loc[row, 'rank'] = re.sub(\"[^0-9]\",\"\", uni_df.loc[row, 'rank'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d53c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',len(uni_df))\n",
    "uni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc9f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rearrange the column arrangement\n",
    "cols = ['rank', 'name', 'country', 'rank_name']\n",
    "uni_df = uni_df[cols]\n",
    "uni_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rank_name column\n",
    "uni_df.drop('rank_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8aeaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "uni_df.rename(columns={'name': 'institution_name'}, inplace=True)\n",
    "uni_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9447053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "uni_df.to_csv('D:\\\\OneDrive\\\\Documents\\\\PERSONAL\\\\PERSONAL DEVELOPMENT\\\\DATA SCIENCE\\\\Personal Project Portfolio\\\\PP00017_Prediction of the Success of Start-Ups Using Unbiased Classification ML Models\\\\data\\\\uni_rankings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_score_m3d(medium_3_data, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99094ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for nog data\n",
    "def fit_and_score_nog(dataset, models):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fits and evaluates models passed to it based on the data structure\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : Dictionary of machine learning models\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    A dictionary of accuracy scores of each model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define preprocessors\n",
    "\n",
    "    # pipeline for text data1\n",
    "    text1_features = 'short_description_o'\n",
    "    text1_transformer = Pipeline(steps=[\n",
    "        ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "    ])\n",
    "\n",
    "    # pipeline for text data2\n",
    "    text2_features = 'description_o'\n",
    "    text2_transformer = Pipeline(steps=[\n",
    "        ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "    ])\n",
    "\n",
    "    # pipeline for text data3\n",
    "    text3_features = 'description_o'\n",
    "    text3_transformer = Pipeline(steps=[\n",
    "        ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "    ])\n",
    "\n",
    "    # pipeline for categorical data\n",
    "\n",
    "    no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                           'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "    no_gender_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "\n",
    "    # pipeline for numeric data\n",
    "    numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                         'degree_length','employee_count_min','employee_count_max']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tex1\", text1_transformer, text1_features),\n",
    "            (\"tex2\", text2_transformer, text2_features),\n",
    "            (\"tex3\", text3_transformer, text3_features),\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"nog\", no_gender_transformer, no_gender_features),\n",
    "        ])\n",
    "\n",
    "    X = dataset.drop('success',axis=1)\n",
    "    y = dataset['success']\n",
    "\n",
    "    # Split into train and test dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Make a dictionary to keeo model scores\n",
    "    model_score = {}\n",
    "\n",
    "    # Lopp through models\n",
    "    for name, model in models.items():\n",
    "\n",
    "        # Fit the model to the data\n",
    "        clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        model_score[f'nog_{name}'] = f'{clf.score(X_test, y_test):.3f}%'\n",
    "\n",
    "    model_score = {k:[v] for k,v in model_score.items()}\n",
    "    model_score_df =pd.DataFrame(model_score)\n",
    "\n",
    "    return model_score_df.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_score_nog(no_gender_data, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb91922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for full data\n",
    "def fit_and_score_num(dataset, models):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fits and evaluates models passed to it based on the data structure\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : Dictionary of machine learning models\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    A dictionary of accuracy scores of each model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # pipeline for numeric data\n",
    "    numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                         'degree_length','employee_count_min','employee_count_max']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "\n",
    "            (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "        ])\n",
    "\n",
    "    X = dataset.drop('success',axis=1)\n",
    "    y = dataset['success']\n",
    "\n",
    "    # Split into train and test dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Make a dictionary to keeo model scores\n",
    "    model_score = {}\n",
    "\n",
    "    # Lopp through models\n",
    "    for name, model in models.items():\n",
    "\n",
    "        # Fit the model to the data\n",
    "        clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        model_score[f'num_{name}'] = f'{clf.score(X_test, y_test):.3f}%'\n",
    "\n",
    "    model_score = {k:[v] for k,v in model_score.items()}\n",
    "    model_score_df =pd.DataFrame(model_score)\n",
    "\n",
    "    return model_score_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_score_num(num_data, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb11a85",
   "metadata": {},
   "source": [
    "## We will carry out hyperparameter tuning and also evaluate for the folllowing as stated earlier:\n",
    "\n",
    "* Hyperparamenter tuning\n",
    "* Feature Importance\n",
    "* Confusion Matrix\n",
    "* Cross-validation\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* Classification Report\n",
    "* ROC curve\n",
    "* Area under the C curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use RandomizedSearchCV due to limited time to deploy Gridsearch CV\n",
    "\n",
    "# Create a hyperparameter grid for Logistic Regression\n",
    "log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "                'clf__C': np.logspace(-4,4,20),\n",
    "                'clf__solver':['lbfgs','liblinear'],\n",
    "               'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "# Create a hyperparameter grid for SVC\n",
    "svc_grid = {'clf__C': [0.1, 1, 10, 1000], \n",
    "           'clf__degree':[0, 1, 2, 3, 4, 5, 6],\n",
    "           'clf__kernel':['linear', 'rbf', 'poly']}\n",
    "\n",
    "\n",
    "\n",
    "# Create a hyperparameter grid for Random Forest\n",
    "rf_grid = {'clf__n_estimators': np.arange(10,1000,50),\n",
    "          'clf__max_depth': [None, 3, 5, 10],\n",
    "          'clf__min_samples_split': np.arange(2, 20, 2),\n",
    "          'clf__min_samples_leaf': np.arange(1, 20, 2)}\n",
    "\n",
    "# Create a hyperparameter grid for Naive Bayes\n",
    "nb_grid ={'clf__alpha':[0.1, 1, 10, 1000],\n",
    "          'clf__fit_prior': [True,False]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268ea32",
   "metadata": {},
   "source": [
    "### Full Data\n",
    "\n",
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eaa7d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg fd is:{model_score}')\n",
    "print(f'Best params for Log_Reg fd is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd1052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run for 'm1d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg m1d is:{model_score}')\n",
    "print(f'Best params for Log_Reg is m1d:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe441df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm2d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg m2d is:{model_score}')\n",
    "print(f'Best params for Log_Reg m2d is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg m3d is:{model_score}')\n",
    "print(f'Best params for Log_Reg m3d is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg nog is:{model_score}')\n",
    "print(f'Best params for Log_Reg nog is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg num is:{model_score}')\n",
    "print(f'Best params for Log_Reg num is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd407f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg ned is:{model_score}')\n",
    "print(f'Best params for Log_Reg ned is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2103073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg sed is:{model_score}')\n",
    "print(f'Best params for Log_Reg sed is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=log_reg_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for log_reg fed is:{model_score}')\n",
    "print(f'Best params for Log_Reg fed is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f6546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836242b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767bb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b4208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be1186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c405397",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aca0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC fd is:{model_score}')\n",
    "print(f'Best params for SVC fd is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5976b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    " = medium_1_data['success']\n",
    "\n",
    "   ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC m1d is:{model_score}')\n",
    "print(f'Best params for SVC m1d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2914981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm2d' data\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC m2d is:{model_score}')\n",
    "print(f'Best params for SVC m2d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86776a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "#rand_params =[log_reg_grid,svc_grid,rf_grid,nb_grid]\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC m3d is:{model_score}')\n",
    "print(f'Best params for SVC m3d is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC nog is:{model_score}')\n",
    "print(f'Best params for SVC nog is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC num is:{model_score}')\n",
    "print(f'Best params for SVC num is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC ned is:{model_score}')\n",
    "print(f'Best params for SVC ned is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9695206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC sed is:{model_score}')\n",
    "print(f'Best params for SVC sed is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=svc_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for SVC fed is:{model_score}')\n",
    "print(f'Best params for SVC fed is:{clf_best}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651a261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eafed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "922bea24",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8207739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for full data\n",
    "\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF fd is:{model_score}')\n",
    "print(f'Best params for RF fd is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10431da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "   ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF m1d is:{model_score}')\n",
    "print(f'Best params for RF m1d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm2d' data\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF m2d is:{model_score}')\n",
    "print(f'Best params for RF m2d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF m3d is:{model_score}')\n",
    "print(f'Best params for RF m3d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF nog is:{model_score}')\n",
    "print(f'Best params for RF nog is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec942063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF num is:{model_score}')\n",
    "print(f'Best params for RF num is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF ned is:{model_score}')\n",
    "print(f'Best params for RF ned is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF sed is:{model_score}')\n",
    "print(f'Best params for RF sed is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=rf_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for RF fed is:{model_score}')\n",
    "print(f'Best params for RF fed is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb76714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c33847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b04ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77ace5be",
   "metadata": {},
   "source": [
    "**Naives Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for full data\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB fd is:{model_score}')\n",
    "print(f'Best params for NB fd is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm1d' data\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "   ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB m1d is:{model_score}')\n",
    "print(f'Best params for NB m1d is:{clf_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm2d' data\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB m2d is:{model_score}')\n",
    "print(f'Best params for NB m2d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB m3d is:{model_score}')\n",
    "print(f'Best params for NB m3d is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43690f7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB nog is:{model_score}')\n",
    "print(f'Best params for NB nog is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB num is:{model_score}')\n",
    "print(f'Best params for NB num is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB ned is:{model_score}')\n",
    "print(f'Best params for NB ned is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB sed is:{model_score}')\n",
    "print(f'Best params for NB sed is:{clf_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c19430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# log_reg_grid = {'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                 'clf__C': np.logspace(-4,4,20),\n",
    "#                 'clf__solver':['lbfgs','liblinear'],\n",
    "#                'clf__max_iter': np.arange(100,300,50)}\n",
    "\n",
    "clf_model = RandomizedSearchCV(clf, param_distributions=nb_grid, cv=5, n_iter=20,verbose=True) \n",
    "\n",
    "clf_model.fit(X_train, y_train)\n",
    "clf_best = clf_model.best_estimator_\n",
    "\n",
    "model_score = clf_model.score(X_test, y_test)\n",
    "best_params  =  clf_best\n",
    "\n",
    "\n",
    "print(f'RandomizedSearchCV score for NB fed is:{model_score}')\n",
    "print(f'Best params for NB fed is:{clf_best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56718ef8",
   "metadata": {},
   "source": [
    "### Final Experiments\n",
    "\n",
    "Using the best parameters from the hyperparameter tuning, we will now model and evaluate each using the evaluation techniques for each model for each of the  9 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaa8a8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c937598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg fd is {clf.score(X_test, y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "\n",
    "def plot_conf_mat(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using seaborn's heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, y_preds ),\n",
    "                    annot=True,\n",
    "                    cbar=False,\n",
    "                    fmt='.0f')\n",
    "    plt.xlabel('True label')\n",
    "    plt.ylabel('Predicted label')\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab47c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9097304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f32980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa62732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_fd)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg fd is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_fd)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ee7e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg m1d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_m1d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm2d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg m2d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_m2d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9ec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22622ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg m3d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_m3d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c50a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg nog is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_nog)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c4488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefeea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg num is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_num)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg ned is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_ned)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1a8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97699a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg sed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_sed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0ef54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "plot_roc_curve(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for log_reg fed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_fed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517beda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4508e3ae",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d86d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC fd is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_fd)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75202ceb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e31c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC m1d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_m1d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83197706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm2d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC m2d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_m2d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41759e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC m3d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_m3d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f101949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC nog is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_nog)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fe104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=1, degree=0))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC num is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_num)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c9484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC ned is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_ned)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19537f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC sed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (SVC_sed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9304cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", SVC(C=0.1))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for SVC fed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic Reg_fed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feea9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e54c05",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f471bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=10, min_samples_leaf=3,\n",
    "                                        min_samples_split=16,\n",
    "                                        n_estimators=710))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_fd is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_fd)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41941796",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\",  RandomForestClassifier(max_depth=5, min_samples_split=18,\n",
    "                                        n_estimators=610))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_m1d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_m1d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370212d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee80795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm2d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=5, min_samples_split=18,\n",
    "                                        n_estimators=610))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_SVC m2d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_m2d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8507f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3225d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=5, min_samples_split=18,\n",
    "                                        n_estimators=610))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_m3d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_m3d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359130c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb39608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=10, min_samples_leaf=3,\n",
    "                                        min_samples_split=16,\n",
    "                                        n_estimators=710))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_nog is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_nog)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01eb96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=3, min_samples_leaf=7,\n",
    "                                        min_samples_split=6,\n",
    "                                        n_estimators=560))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_num is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_num)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97a959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=10, min_samples_leaf=3,\n",
    "                                        min_samples_split=16,\n",
    "                                        n_estimators=710))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_ned is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_ned)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307960c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb07389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\",RandomForestClassifier(max_depth=10, min_samples_split=18,\n",
    "                                        n_estimators=910))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_sed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (rf_sed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aeedbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8688b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", RandomForestClassifier(max_depth=10, min_samples_leaf=3,\n",
    "                                        min_samples_split=16,\n",
    "                                        n_estimators=710))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for rf_fed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (logistic rf_fed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c0278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78a8648a",
   "metadata": {},
   "source": [
    "## Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_fd is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_fd)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f6e5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'm1d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "X = medium_1_data.drop('success',axis=1)\n",
    "y = medium_1_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=1000, fit_prior=False))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_m1d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_m1d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4273bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm2d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_2_features = ['status','category_list','category_groups_list','uuid_p','gender',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_2_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat2\", categorical_2_transformer, categorical_2_features),\n",
    "])\n",
    "\n",
    "\n",
    "X = medium_2_data.drop('success',axis=1)\n",
    "y = medium_2_data['success']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=1000))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_m2d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_m2d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac6fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for 'm3d' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_3_features = ['status','category_list','category_groups_list']\n",
    "\n",
    "categorical_3_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat3\", categorical_3_transformer, categorical_3_features),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "X = medium_3_data.drop('success',axis=1)\n",
    "y = medium_3_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10, fit_prior=False))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_m3d is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_m3d)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4faa3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'nog' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "no_gender_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "no_gender_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"nog\", no_gender_transformer, no_gender_features),\n",
    "    ])\n",
    "\n",
    "X = no_gender_data.drop('success',axis=1)\n",
    "y = no_gender_data['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=1000, fit_prior=False))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_nog is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_nog)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb480d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'num' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "X = num_data.drop('success',axis=1)\n",
    "y = num_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10, fit_prior=False))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_num is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_num)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53709987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf358320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'ned' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = no_enrich_df.drop('success',axis=1)\n",
    "y = no_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_ned is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_ned)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c83a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bae8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'sed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = senti_enrich_df.drop('success',axis=1)\n",
    "y = senti_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_sed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_sed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0c957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fed' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = follow_enrich_df.drop('success',axis=1)\n",
    "y = follow_enrich_df['success']\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", MultinomialNB(alpha=10))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Plot the ROC curve and calculate the AUC metric\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy score for NB_fed is {clf.score(X_test, y_test)}')\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)\n",
    "\n",
    "# Calculate the classification report \n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Calculate the cross validated accuracy \n",
    "cv_acc = cross_val_score(clf,  X, y, cv=5, scoring='accuracy')\n",
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc\n",
    "\n",
    "# Calculate the cross validated precision\n",
    "cv_precision = cross_val_score(clf,  X, y, cv=5, scoring='precision')\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision\n",
    "\n",
    "# Calculate the cross validated recall \n",
    "cv_recall = cross_val_score(clf,  X, y, cv=5, scoring='recall')\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall\n",
    "\n",
    "# Calculate the cross validated F1 score\n",
    "cv_f1 = cross_val_score(clf,  X, y, cv=5, scoring='f1')\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1\n",
    "\n",
    "# Visualize cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({'Accuracy':cv_acc,\n",
    "                          'Precision': cv_precision,\n",
    "                          'Recall': cv_recall,\n",
    "                          'F1': cv_f1}, index=[0])\n",
    "cv_metrics.T.plot.bar(title='Cross-validated metrics (NB_fed)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4051b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "272d60fa",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for 'fd' data:\n",
    "\n",
    "# Define preprocessors\n",
    "\n",
    "# pipeline for text data1\n",
    "text1_features = 'short_description_o'\n",
    "text1_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data2\n",
    "text2_features = 'description_o'\n",
    "text2_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for text data3\n",
    "text3_features = 'description_o'\n",
    "text3_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "\n",
    "categorical_features = ['country_code_o', 'status','category_list','category_groups_list','uuid_p','gender','country_code_p',\n",
    "                       'featured_job_title','institution_name','degree_type','subject','is_completed']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline for numeric data\n",
    "numeric_features = ['following', 'followers','polarity','subjectivity','rank_o','rank_p','num_events_part','per_exp_at_coy_start',\n",
    "                     'degree_length','employee_count_min','employee_count_max']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tex1\", text1_transformer, text1_features),\n",
    "        (\"tex2\", text2_transformer, text2_features),\n",
    "        (\"tex3\", text3_transformer, text3_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "X = full_data.drop('success',axis=1)\n",
    "y = full_data['success']\n",
    "\n",
    "\n",
    "# Split into train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make a dictionary to keep model scores\n",
    "model_score = {}\n",
    "best_params = {}\n",
    "\n",
    "# Fit the model to the data\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", LogisticRegression(C=0.23357214690901212, max_iter=150,\n",
    "                                    penalty='l1', solver='liblinear'))])\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1eee8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = clf.preprocessor.named_steps[\"vectorizer\"].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5ef1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
